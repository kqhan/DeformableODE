<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Deformable NeuralODE</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Deformable NeuralODE: Neural Ordinary Differential Equation for Deformable Dynamic System Prediction</h1>
                    <h3 class="title is-4 conference-authors">CS 269 S25</h3>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">
                            Kaiqiao&#160;Han,
                            Zhi&#160;Li
                            </span>
                    </div>


                    <div class="column has-text-centered">
                        <div class="publication-links">
<!--                            <span class="link-block">-->
<!--                <a target="_blank" href="https://arxiv.org/abs/2210.03094"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="ai ai-arxiv"></i>-->
<!--                  </span>-->
<!--                  <span>arXiv</span>-->
<!--                </a>-->
<!--              </span>-->

                            <span class="link-block">
                <a target="_blank" href="assets/Deformable_NeurlODE.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
              </span>
                            <!-- Code Link. -->
                            <span class="link-block">
                <a target="_blank" href="https://github.com/kqhan/DeformableODE"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
<!--                <a target="_blank" href="https://github.com/vimalabs/VIMA#pretrained-models"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fa fa-network-wired"></i>-->
<!--                  </span>-->
<!--                  <span>Models</span>-->
<!--                </a>-->
<!--                <a target="_blank" href="https://github.com/vimalabs/VimaBench"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fas fa-robot"></i>-->
<!--                  </span>-->
<!--                  <span>Benchmark</span>-->
<!--                </a>-->
<!--                <a target="_blank" href="https://huggingface.co/datasets/VIMA/VIMA-Data"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fas fa-database"></i>-->
<!--                  </span>-->
<!--                  <span>Dataset</span>-->
<!--                </a>-->
              </span>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p style="font-size: 125%">
                        Deformable dynamic systems, prevalent in domains such as soft robotics, biological tissue
                        modeling, and deformable image registration, pose significant challenges due to their nonlinear,
                        time-varying, and often non-smooth behaviors. Traditional physical models struggle with
                        adaptability, while deep learning models, such as Neural Ordinary Differential Equations
                        (NeuralODEs), lack explicit spatial and physical modeling capabilities. We propose Deformable
                        NeuralODE, a hybrid framework that integrates Transformer-based encoding, graph neural networks,
                        and NeuralODEs to learn continuous-time dynamics of deformable systems from partial observations.
                        Our model introduces time-aware latent encoding to capture the correlation of the objects.
                        Experimental evaluations on real-world deformation data demonstrate that Deformable
                        NeuralODE's effectiveness, offering a robust tool for accurate long-term deformation prediction.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>


<!--Model-->
<section class="section">
    <div class="container is-max-widescreen">
        <div class="rows">
            <div class="rows is-centered ">
                <div class="row is-full-width">
                    <h2 class="title is-3"><span class="dvima">Task: Falling deformable objects</span></h2>
                    <video poster="" autoplay controls muted loop height="100%">
                        <source src="assets/videos/run_combine.mp4"
                                type="video/mp4">
                    </video>
                    <br>
                    <span style="font-size: 110%">
                         Each episode starts with 5 deformable onjects:
                        a sphere, cuboid, cylinder, capsule and cone, spawned at heights and fall into a rigid bucket.
                        Once released, the objects accelerate under gravity and rebound against the rigid bucket walls,
                        collide with one another, and repeatedly impact the bucket floor.
                    </span>
                </div>
            </div>

        </div>
    </div>
</section>



<!--Conclusion-->
<!--<section class="section">-->
<!--    <div class="container is-max-widescreen">-->
<!--        <div class="rows">-->
<!--            <div class="rows is-centered ">-->
<!--                <div class="row is-full-width">-->
<!--                    <h2 class="title is-3"><span-->
<!--                            class="dvima">Conclusion</span></h2>-->

<!--                    <p style="font-size: 125%">-->
<!--                        In this work, we introduce a novel <i>multimodal</i> prompting formulation that converts diverse-->
<!--                        robot manipulation tasks into a uniform sequence modeling problem. We instantiate this-->
<!--                        formulation in VIMA-Bench, a diverse benchmark with multimodal tasks and systematic evaluation-->
<!--                        protocols for generalization. We propose VIMA, a conceptually simple transformer-based agent-->
<!--                        capable of solving tasks such as visual goal reaching, one-shot video imitation, and novel-->
<!--                        concept grounding with a single model. Through comprehensive experiments, we show that VIMA-->
<!--                        exhibits strong model scalability and zero-shot generalization. Therefore, we recommend our-->
<!--                        agent design as a solid starting point for future work.-->
<!--                    </p>-->

<!--                </div>-->
<!--            </div>-->

<!--        </div>-->
<!--    </div>-->
<!--</section>-->


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column">
                <div class="content has-text-centered">
                    <p>
                        Website template borrowed from <a
                            href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> and <a
                            href="https://github.com/cliport/cliport.github.io">CLIPort</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>